{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_timestamp, unix_timestamp, lag\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "#from pyspark.sql.functions import col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"BitcoinPricePrediction\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "\n",
    "response = es.search(index=\"historical\", body={\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    },\n",
    "    \"size\": 1000  \n",
    "})\n",
    "\n",
    "data = [hit[\"_source\"] for hit in response[\"hits\"][\"hits\"]]\n",
    "\n",
    "spark = SparkSession.builder.appName(\"BitcoinPricePrediction\").getOrCreate()\n",
    "\n",
    "training_df = spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering lag \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.orderBy(\"time_numeric\")\n",
    "\n",
    "training_df = training_df.withColumn(\"BTC_lag_1\", lag(\"BTC_close\", 1).over(window_spec))\n",
    "training_df = training_df.withColumn(\"BTC_lag_3\", lag(\"BTC_close\", 3).over(window_spec))\n",
    "training_df = training_df.withColumn(\"ETH_lag_1\", lag(\"ETH_close\", 1).over(window_spec))\n",
    "training_df = training_df.withColumn(\"ETH_lag_3\", lag(\"ETH_close\", 3).over(window_spec))\n",
    "\n",
    "training_df = training_df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For time series models (such as Bitcoin predictions), randomSplit() is not ideal because future values are not randomly distributed. Instead, a rolling split should be used so that the model learns only from past data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 797 rows, Test: 200 rows\n"
     ]
    }
   ],
   "source": [
    "training_df = training_df.orderBy(\"time_numeric\")\n",
    "split_index = int(training_df.count() * 0.8)\n",
    "train_data = training_df.limit(split_index)\n",
    "test_data = training_df.subtract(train_data)\n",
    "\n",
    "print(f\"Train: {train_data.count()} rows, Test: {test_data.count()} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seperate features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_features = train_data.drop(\"BTC_close\")\n",
    "#test_data_features = test_data.drop(\"BTC_close\")\n",
    "\n",
    "#train_data_features.show(2)\n",
    "#test_data_features.show(2)\n",
    "\n",
    "#train_data_label = train_data.select(\"time_numeric\", \"BTC_close\")\n",
    "\n",
    "#train_data_label.show(5)\n",
    "\n",
    "#test_data_label = test_data.select(\"time_numeric\", \"BTC_close\")\n",
    "\n",
    "#test_data_label.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+--------------------+------------------+----------+---------+--------------------+------------------+----------+------------+-------------------+---------+---------+---------+---------+--------------------+\n",
      "|     BTC_ETH_ratio|BTC_close|    BTC_price_change|    BTC_volatility|BTC_volume|ETH_close|    ETH_price_change|    ETH_volatility|ETH_volume|time_numeric|          timestamp|BTC_lag_1|BTC_lag_3|ETH_lag_1|ETH_lag_3|independent_features|\n",
      "+------------------+---------+--------------------+------------------+----------+---------+--------------------+------------------+----------+------------+-------------------+---------+---------+---------+---------+--------------------+\n",
      "|30.423582894388584|104601.45|                 0.0| 258.5500000000029|   0.07967|  3438.17|                 0.0|               0.0|    0.2055|  1737306840|2025-01-19T17:14:00|104601.45| 104780.0|  3438.17|  3450.22|[30.4235828943885...|\n",
      "|30.274098463286403| 104452.3|-0.00142588845565...|149.14999999999418|   0.01597|  3450.22|0.003504771433640...|12.049999999999727|    0.2326|  1737306900|2025-01-19T17:15:00|104601.45| 104860.0|  3438.17|  3438.17|[30.2740984632864...|\n",
      "|30.274098463286403| 104452.3|                 0.0|149.14999999999418|   0.01753|  3450.22|                 0.0|12.049999999999727|    0.4673|  1737306960|2025-01-19T17:16:00| 104452.3|104601.45|  3450.22|  3438.17|[30.2740984632864...|\n",
      "|30.349014155786364|104345.07|-0.00102659299986...|107.22999999999593|   0.13196|  3438.17|-0.00349253091107...|12.049999999999727|    0.3254|  1737307020|2025-01-19T17:17:00| 104452.3|104601.45|  3450.22|  3438.17|[30.3490141557863...|\n",
      "|30.317327590704362|104601.45|0.002457039896566...| 256.3799999999901|    0.0077|  3450.22|0.003504771433640...|12.049999999999727|    0.1789|  1737307080|2025-01-19T17:18:00|104345.07| 104452.3|  3438.17|  3450.22|[30.3173275907043...|\n",
      "+------------------+---------+--------------------+------------------+----------+---------+--------------------+------------------+----------+------------+-------------------+---------+---------+---------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [\"BTC_ETH_ratio\",  \"BTC_price_change\" , \"BTC_volatility\", \"BTC_volume\", \"ETH_close\", \"ETH_price_change\", \"ETH_volatility\", \"ETH_volume\", \"BTC_lag_1\", \"BTC_lag_3\", \"ETH_lag_1\", \"ETH_lag_3\"]\n",
    "featureassembler = VectorAssembler(inputCols=feature_cols,outputCol=\"independent_features\")\n",
    "train_data = featureassembler.transform(train_data)\n",
    "test_data = featureassembler.transform(test_data)\n",
    "print(train_data.show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Output column scaled_features already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler(inputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindependent_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscaled_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m scaler_model \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m train_data \u001b[38;5;241m=\u001b[39m scaler_model\u001b[38;5;241m.\u001b[39mtransform(train_data)\n\u001b[1;32m      5\u001b[0m test_data \u001b[38;5;241m=\u001b[39m scaler_model\u001b[38;5;241m.\u001b[39mtransform(test_data)\n",
      "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/ml/wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/ml/wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Output column scaled_features already exists."
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(inputCol=\"independent_features\", outputCol=\"scaled_features\")\n",
    "scaler_model = scaler.fit(train_data)\n",
    "\n",
    "train_data = scaler_model.transform(train_data)\n",
    "test_data = scaler_model.transform(test_data)\n",
    "\n",
    "train_data.show(truncate=False)\n",
    "test_data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalized_train_data_output = train_data_feature.join(train_data_label, on=\"time_numeric\")\n",
    "#finalized_test_data_output = train_data_feature.join(train_data_label, on=\"time_numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalized_train_data_output.show(2, truncate=False)\n",
    "#finalized_test_data_output.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|     scaled_features|BTC_close|\n",
      "+--------------------+---------+\n",
      "|[0.76877820614125...|104601.45|\n",
      "|[0.76362530491760...| 104452.3|\n",
      "|[0.76362530491760...| 104452.3|\n",
      "|[0.76620773548049...|104345.07|\n",
      "|[0.76511546293558...|104601.45|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "finalized_train_data_output = train_data.select(\"scaled_features\",\"BTC_close\")\n",
    "print(finalized_train_data_output.show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "regressor = LinearRegression(featuresCol=\"scaled_features\", labelCol=\"BTC_close\")\n",
    "regressor = regressor.fit(finalized_train_data_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+--------------------+------------------+----------+---------+--------------------+------------------+----------+------------+-------------------+---------+---------+---------+---------+--------------------+--------------------+------------------+\n",
      "|     BTC_ETH_ratio|BTC_close|    BTC_price_change|    BTC_volatility|BTC_volume|ETH_close|    ETH_price_change|    ETH_volatility|ETH_volume|time_numeric|          timestamp|BTC_lag_1|BTC_lag_3|ETH_lag_1|ETH_lag_3|independent_features|     scaled_features|        prediction|\n",
      "+------------------+---------+--------------------+------------------+----------+---------+--------------------+------------------+----------+------------+-------------------+---------+---------+---------+---------+--------------------+--------------------+------------------+\n",
      "| 31.20574822646554|102712.16|                 0.0|12.839999999996508|     0.001|  3291.45|-0.00733764001230...|25.550000000000182|    0.0824|  1737354660|2025-01-20T06:31:00|102712.16|102519.55|  3315.78|  3311.23|[31.2057482264655...|[0.79574034973732...|102729.51400667884|\n",
      "|31.189749662218578| 102725.0|1.250095412266283...|12.839999999996508|    9.0E-4|  3293.55|6.380166795789677E-4|24.330000000000382|    0.1915|  1737354720|2025-01-20T06:32:00|102712.16| 102725.0|  3291.45|  3290.23|[31.1897496622185...|[0.79518886072487...|102725.14122989001|\n",
      "|31.189749662218578| 102725.0|                 0.0|12.839999999996508|   0.00119|  3293.55|                 0.0| 2.100000000000364|       0.0|  1737354780|2025-01-20T06:33:00| 102725.0|102712.16|  3293.55|  3315.78|[31.1897496622185...|[0.79518886072487...|102765.10045304128|\n",
      "|31.178484493465344| 102725.0|                 0.0|               0.0|     0.002|  3294.74|3.613122618451037E-4|1.1899999999995998|    0.2766|  1737354840|2025-01-20T06:34:00| 102725.0|102712.16|  3293.55|  3291.45|[31.1784844934653...|[0.79480053732942...|102753.18675261576|\n",
      "| 33.39314680631812| 102725.0|                 0.0|               0.0|       0.0|  3076.23| -0.0663208629512495|218.50999999999976|    0.1424|  1737354900|2025-01-20T06:35:00| 102725.0| 102725.0|  3294.74|  3293.55|[33.3931468063181...|[0.87114250858168...|103663.70784198085|\n",
      "| 30.69636978730124|101080.69|-0.01600691165733...|1644.3099999999977|   0.06997|  3292.92| 0.07044011663627225|218.50999999999976|    0.2023|  1737354960|2025-01-20T06:36:00| 102725.0| 102725.0|  3076.23|  3293.55|[30.6963697873012...|[0.77818148582677...|101272.21535980582|\n",
      "| 31.17990402447649| 102725.0| 0.01626730090584072|1644.3099999999977|   0.01328|  3294.59|5.071486704808503E-4|218.36000000000013|      0.02|  1737355020|2025-01-20T06:37:00|101080.69| 102725.0|  3292.92|  3294.74|[31.1799040244764...|[0.79484947020510...|101223.67508311082|\n",
      "| 31.17990402447649| 102725.0|                 0.0|1644.3099999999977|   0.00253|  3294.59|                 0.0|1.6700000000000728|       0.0|  1737355080|2025-01-20T06:38:00| 102725.0| 102725.0|  3294.59|  3076.23|[31.1799040244764...|[0.79484947020510...|102405.15771519886|\n",
      "|31.112100479439817| 102725.0|                 0.0|               0.0|   0.20292|  3301.77|0.002179330356736342| 7.179999999999836|      0.04|  1737355140|2025-01-20T06:39:00| 102725.0|101080.69|  3294.59|  3292.92|[31.1121004794398...|[0.79251220359071...|102749.26788439686|\n",
      "| 31.06904563813212|102694.07|-3.01095156972408...|30.929999999993015|   0.14139|  3305.35|0.001084266923498...|10.759999999999764|    0.0875|  1737355200|2025-01-20T06:40:00| 102725.0| 102725.0|  3301.77|  3294.59|[31.0690456381321...|[0.79102805341652...|102688.58349036975|\n",
      "+------------------+---------+--------------------+------------------+----------+---------+--------------------+------------------+----------+------------+-------------------+---------+---------+---------+---------+--------------------+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 540.9364086765158\n",
      "RMSE: 696.6081724404379\n",
      "R²: 0.9025110387098105\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"BTC_close\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"BTC_close\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "\n",
    "# R-squared (R²)\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"BTC_close\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "# Display results\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m regressor\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mtrain_data_output\u001b[49m)\n\u001b[1;32m      5\u001b[0m pdf \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBTC_close\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtoPandas()\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m700\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(pdf\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_output' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions = regressor.transform(train_data_output)\n",
    "\n",
    "pdf = predictions.select(\"timestamp\", \"BTC_close\", \"prediction\").toPandas().head(700)\n",
    "\n",
    "print(pdf.head(2))\n",
    "\n",
    "#pdf[\"time\"] = pdf[\"independent_features\"].apply(lambda x: x[0]) \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(pdf[\"timestamp\"], pdf[\"BTC_close\"], label=\"Actual Price\", marker=\"o\", linestyle=\"dashed\")\n",
    "plt.plot(pdf[\"timestamp\"], pdf[\"prediction\"], label=\"Predicted Price\", marker=\"s\", linestyle=\"solid\")\n",
    "\n",
    "plt.xlabel(\"Time (Unix Timestamp)\")\n",
    "plt.ylabel(\"Bitcoin Price\")\n",
    "plt.title(\"Bitcoin Price Prediction\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  BTC_close     prediction  signal profit\n",
      "0  2025-01-19T17:14:00  104601.45  104299.210540   False    NaN\n",
      "1  2025-01-19T17:15:00  104452.30  104164.944952   False   -0.0\n",
      "2  2025-01-19T17:16:00  104452.30  104070.486469   False    0.0\n",
      "3  2025-01-19T17:17:00  104345.07  104081.462301   False   -0.0\n",
      "4  2025-01-19T17:18:00  104601.45  104080.022204   False    0.0\n",
      "29330.129999999932\n"
     ]
    }
   ],
   "source": [
    "pdf[\"signal\"] = pdf[\"prediction\"] > pdf[\"BTC_close\"]\n",
    "\n",
    "pdf[\"profit\"] = pdf[\"BTC_close\"].diff() * pdf[\"signal\"].shift(1).fillna(0)\n",
    "\n",
    "print(pdf.head(5))\n",
    "\n",
    "total_earnings = pdf[\"profit\"].sum()\n",
    "\n",
    "print(total_earnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor.save(\"regression_model version 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
